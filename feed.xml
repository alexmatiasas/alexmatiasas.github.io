<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://alexmatiasas.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://alexmatiasas.github.io/" rel="alternate" type="text/html" /><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/feed.xml</id><title type="html">Manuel Alejandro Matías Astorga | Data Science Portfolio – Machine Learning &amp;amp; AI Projects</title><subtitle>A showcase of my Data Science and Machine Learning projects.</subtitle><author><name>Manuel Alejandro Matías Astorga</name></author><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-image-classification/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-image-classification</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-image-classification/"><![CDATA[<h1 id="language-model-project">Language model Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to construct an image classificator.</p>

<!-- 

- Utiliza redes neuronales convolucionales (CNN) para clasificar imágenes en diferentes categorías.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<!-- 
Proyecto 2: Clasificación de Imágenes de Gatos y Perros (Computer Vision)

Objetivo: Construir un clasificador que identifique si una imagen contiene un gato o un perro usando redes neuronales convolucionales (CNN).

Paso a Paso

	1.	Definición del Problema y Recolección de Datos
	•	Objetivo: Distinguir entre imágenes de gatos y perros.
	•	Datos: Usa datasets de Kaggle como el de gatos y perros de Microsoft (disponible en la plataforma Kaggle).
	2.	Exploración de Datos
	•	Examina el dataset para ver ejemplos de cada clase (gatos y perros).
	•	Balance de clases: Revisa si hay una cantidad similar de imágenes de cada categoría.
	3.	Preprocesamiento de Imágenes
	•	Redimensionamiento: Redimensiona las imágenes a un tamaño manejable (ej., 128x128 píxeles).
	•	Normalización: Escala los valores de píxeles entre 0 y 1 para facilitar el entrenamiento.
	•	Data Augmentation: Aplica transformaciones (rotación, zoom, desplazamiento) para mejorar la generalización del modelo.
	4.	Arquitectura del Modelo CNN
	•	Usa una arquitectura CNN básica con capas convolucionales, de pooling y completamente conectadas.
	•	Transfer Learning: Experimenta con modelos preentrenados como VGG16 o ResNet para mejorar el rendimiento.
	5.	Entrenamiento del Modelo
	•	Usa una división en entrenamiento, validación y prueba.
	•	Ajusta hiperparámetros clave como batch size, learning rate, y número de épocas.
	6.	Evaluación del Modelo
	•	Usa métricas como accuracy y curvas ROC/AUC para evaluar el rendimiento.
	•	Visualiza predicciones incorrectas para analizar posibles mejoras en el modelo.
	7.	Despliegue y Visualización
	•	API de Inferencia: Crea una API para cargar una imagen y recibir la predicción (si es un gato o un perro).
	•	Crea un dashboard de clasificación interactivo donde se muestre la imagen cargada y la predicción del modelo.
 -->

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-image-recognition/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-image-recognition</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-image-recognition/"><![CDATA[<h1 id="image-recognition-project">Image recognition Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to construct a recognizer of images.</p>

<!-- 

- Usa OpenCV para reconocimiento facial o para detección de emociones.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-language-model/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-language-model</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-language-model/"><![CDATA[<h1 id="language-model-project">Language model Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to construct a language model.</p>

<!-- 

- Trabaja en proyectos como clasificación de texto, chatbots o implementa un modelo de transformers como GPT.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-object-detection/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-object-detection</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-object-detection/"><![CDATA[<h1 id="object-detection-project">Object detection Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to construct a text generator.</p>

<!-- 

- Implementa un modelo como YOLO o Faster R-CNN para detectar objetos en imágenes o videos.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-real-time-data-processing/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-real-time-data-processing</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-real-time-data-processing/"><![CDATA[<h1 id="real-time-data-processing-project">Real time data processing Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to analize real time data.</p>

<!-- 

-  Usa Apache Kafka o Spark Streaming para procesar datos en tiempo real.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-recomendation-system/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-recomendation-system</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-recomendation-system/"><![CDATA[<h1 id="recommendation-system-project">Recommendation system Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to recommend things.</p>

<!-- 

-  Usa matrices de similitud o modelos basados en contenido.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<!-- 
Proyecto 3: Sistema de Recomendación para Productos en E-commerce

Objetivo: Construir un sistema de recomendación que sugiera productos a los usuarios en función de sus interacciones anteriores.

Paso a Paso

	1.	Definición del Problema y Recolección de Datos
	•	Objetivo: Crear recomendaciones personalizadas de productos para los usuarios.
	•	Datos: Usa datasets de e-commerce como Retailrocket o Amazon Product Data en Kaggle o los datasets de MovieLens (para sistemas de recomendación basados en películas).
	2.	Exploración y Limpieza de Datos
	•	Análisis de patrones de usuario: Examina cómo interactúan los usuarios con los productos.
	•	Filtrado de datos: Elimina elementos o usuarios con pocas interacciones (para evitar ruido).
	3.	Selecciona un Enfoque de Recomendación
	•	Filtrado colaborativo: Basado en las interacciones de los usuarios.
	•	Filtrado basado en contenido: Basado en las características de los productos.
	•	Modelos híbridos: Combinan filtrado colaborativo y basado en contenido.
	4.	Desarrollo del Modelo
	•	Filtrado colaborativo:
	•	Usa matrices de similitud para calcular qué productos son similares a los que el usuario ha comprado o valorado.
	•	Implementa un modelo de factorización de matrices como SVD para crear recomendaciones.
	•	Basado en contenido:
	•	Vectoriza características de productos usando TF-IDF o CountVectorizer (en caso de productos con descripciones textuales).
	•	Calcula similitudes entre los productos usando cosine similarity.
	5.	Entrenamiento y Optimización del Modelo
	•	Optimiza la matriz de recomendaciones utilizando cross-validation para evitar sobreajuste.
	•	Experimenta con tuning de hiperparámetros en los modelos de recomendación.
	6.	Evaluación del Modelo
	•	Usa métricas como Precision@K y Recall@K para evaluar el modelo.
	•	Compara modelos de filtrado colaborativo con otros enfoques para encontrar el mejor ajuste.
	7.	Despliegue
	•	API de Recomendación: Despliega el sistema en una API que pueda recibir un usuario como entrada y devolver recomendaciones personalizadas.
	•	Dashboard Interactivo: Muestra las recomendaciones y la información del producto en una interfaz visual (por ejemplo, usando Streamlit o Plotly Dash).
 -->

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-sentiment-analysis/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-sentiment-analysis</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-sentiment-analysis/"><![CDATA[<h1 id="sentiment-analysis-project">Sentiment Analysis Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project analyzes a large dataset of <a href="https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews">50,000 movie reviews from IMDb</a>, classifying them into positive or negative sentiments. It is designed to demonstrate NLP preprocessing, exploratory data analysis, and sentiment quantification using R. The project is fully documented in an .Rmd report with visualizations and interactive elements.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-text-generation/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-text-generation</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-text-generation/"><![CDATA[<h1 id="text-generator-project">Text generator Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to construct a text generator.</p>

<!-- 

-  Construye un generador de texto usando un modelo LSTM o un Transformer.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2016-07-20-use-patterns/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2016-07-20-use-patterns</id><content type="html" xml:base="https://alexmatiasas.github.io/2016-07-20-use-patterns/"><![CDATA[<h1 id="use-patterns-project">Use patterns Project</h1>

<h2 id="project-overview">Project Overview</h2>
<p>This project uses machine learning algorithms to detect use patterns.</p>

<!-- 

-  Procesa grandes cantidades de logs de servidor para detectar patrones de uso.
	•	Ingeniería de características: Trabaja en mejorar la calidad de los datos de entrada.
	•	Tuning de hiperparámetros: Experimenta con la búsqueda de hiperparámetros (Grid Search, Random Search) y técnicas como optimización bayesiana.

 -->

<h2 id="dataset-and-preprocessing">Dataset and Preprocessing</h2>
<p>Here you can describe the dataset, preprocessing steps, and challenges in cleaning the data.</p>

<h2 id="model-and-evaluation">Model and Evaluation</h2>
<p>Outline the models used and display evaluation metrics like accuracy, precision, recall, etc.</p>

<!-- // ![ROC Curve](/assets/images/fraud_detection_roc.png) -->

<h2 id="conclusions">Conclusions</h2>
<p>Summarize the results and future steps.</p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry><entry><title type="html"></title><link href="https://alexmatiasas.github.io/2025-04-21-sentiment-analysis/" rel="alternate" type="text/html" title="" /><published>2025-06-19T16:44:59-06:00</published><updated>2025-06-19T16:44:59-06:00</updated><id>https://alexmatiasas.github.io/2025-04-21-sentiment-analysis</id><content type="html" xml:base="https://alexmatiasas.github.io/2025-04-21-sentiment-analysis/"><![CDATA[<h2 id="-project-overview">🎯 Project Overview</h2>

<p>This project analyzes a dataset of <strong><a href="https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews">50,000 IMDb movie reviews</a></strong>, each labeled as <em>positive</em> or <em>negative</em>. The goal is to classify sentiment through a two-phase workflow:</p>

<ol>
  <li><strong>Exploratory Data Analysis and preprocessing in R</strong></li>
  <li><strong>Sentiment classification modeling and deployment in Python</strong></li>
</ol>

<p>The first phase leverages R’s rich ecosystem for text manipulation and data visualization. The second phase (in progress) will involve training ML models and deploying a classifier using Python.</p>

<hr />

<h2 id="️-tools--libraries">🛠️ Tools &amp; Libraries</h2>

<ul>
  <li><strong>R</strong>: <code class="language-plaintext highlighter-rouge">tidyverse</code>, <code class="language-plaintext highlighter-rouge">tidytext</code>, <code class="language-plaintext highlighter-rouge">ggplot2</code>, <code class="language-plaintext highlighter-rouge">udpipe</code>, <code class="language-plaintext highlighter-rouge">SnowballC</code>, <code class="language-plaintext highlighter-rouge">textstem</code>, <code class="language-plaintext highlighter-rouge">DT</code></li>
  <li><strong>Python</strong> (planned): <code class="language-plaintext highlighter-rouge">scikit-learn</code>, <code class="language-plaintext highlighter-rouge">nltk</code>, <code class="language-plaintext highlighter-rouge">pandas</code>, <code class="language-plaintext highlighter-rouge">matplotlib</code>, <code class="language-plaintext highlighter-rouge">PyTorch</code></li>
  <li><strong>Techniques</strong>: Tokenization, POS tagging, stemming, lemmatization, n-grams, polarity</li>
  <li><strong>Format</strong>: R Markdown (<code class="language-plaintext highlighter-rouge">.Rmd</code>) → HTML (via RPubs)</li>
</ul>

<hr />

<h2 id="-key-explorations">📊 Key Explorations</h2>

<ul>
  <li>Sentiment class distribution and review length analysis</li>
  <li>HTML cleaning, stopword removal, punctuation &amp; casing normalization</li>
  <li><strong>POS tagging</strong> using <code class="language-plaintext highlighter-rouge">udpipe</code></li>
  <li><strong>Stemming</strong> (<code class="language-plaintext highlighter-rouge">SnowballC</code>) and <strong>lemmatization</strong> (<code class="language-plaintext highlighter-rouge">textstem</code>)</li>
  <li><strong>N-gram analysis</strong> for phrase structure insight</li>
</ul>

<hr />

<h2 id="-visualizations-preview">📈 Visualizations Preview</h2>

<p>Some of the visualizations in the EDA notebook include:</p>

<ul>
  <li>Word frequency lollipop charts</li>
  <li>Sentiment-based word clouds</li>
  <li>N-gram distribution (bigrams &amp; trigrams)</li>
  <li>Polarity sentiment barplots</li>
</ul>

<p>🚧 <em>Interactive notebook will be available soon via RPubs.</em></p>

<p>➡️ <a href="https://rpubs.com/tu_usuario/tu_publicacion">Explore the full interactive report here</a></p>

<hr />

<h2 id="-full-exploratory-report">📘 Full Exploratory Report</h2>

<p>🛠️ <em>The full report with interactive visualizations is currently being compiled and will be published shortly on RPubs.</em></p>

<!-- Uncomment and update once published:
🔗 [View the full EDA on RPubs](https://rpubs.com/alexmatiasas/01_EDA)  
_(Hosted via RStudio's RPubs; includes interactive visuals and data breakdown)_
-->

<hr />

<h2 id="-next-steps">🔮 Next Steps</h2>

<ul>
  <li>Export cleaned data to <code class="language-plaintext highlighter-rouge">.csv</code> for model training</li>
  <li>Build classifiers using:
    <ul>
      <li>Logistic Regression &amp; Naive Bayes (baseline)</li>
      <li>Pipeline-based ML models (<code class="language-plaintext highlighter-rouge">scikit-learn</code>)</li>
      <li>Deep learning model using <code class="language-plaintext highlighter-rouge">PyTorch</code> (planned)</li>
    </ul>
  </li>
  <li>Evaluation: <strong>Confusion Matrix</strong>, <strong>F1 Score</strong>, <strong>ROC-AUC</strong></li>
  <li>Optionally deploy via <strong>Streamlit</strong> or <strong>Apache Spark</strong></li>
</ul>

<hr />

<h2 id="-deliverables">🧾 Deliverables</h2>

<h2 id="-deliverables-1">🧾 Deliverables</h2>

<ul>
  <li><a href="https://github.com/alexmatiasas/Sentiment-Analysis/blob/main/notebooks/01_EDA.Rmd"><code class="language-plaintext highlighter-rouge">01_EDA.Rmd</code></a> — Core notebook (R-based)</li>
  <li>Cleaned datasets (stemmed, lemmatized, udpipe); export planned for modeling phase</li>
  <li><em>EDA report (RPubs) — Coming soon</em></li>
  <li><code class="language-plaintext highlighter-rouge">model_sentiment.py</code> — (Coming soon)</li>
  <li>Streamlit or Apache Spark deployment — (Planned)</li>
</ul>

<hr />

<h2 id="-outcome">📌 Outcome</h2>

<blockquote>
  <p>Completed a robust EDA and text processing pipeline in R.<br />
Laying the foundation for cross-platform sentiment classification with Python.</p>
</blockquote>

<hr />

<h2 id="-what-i-learned">🧠 What I Learned</h2>

<ul>
  <li>R is powerful for quick and elegant EDA and text visualization.</li>
  <li>Handling natural language data requires both linguistic and statistical intuition.</li>
  <li>Preprocessing choices (e.g., stemming vs lemmatization) can deeply affect downstream model performance.</li>
</ul>

<p>🔗 <a href="https://github.com/alexmatiasas/Sentiment-Analysis">View this project on GitHub</a></p>

<hr />

<p>📌 <em>Note: This project is currently in Phase 1 (EDA &amp; preprocessing). The modeling and deployment phase will follow shortly.</em></p>

<p><em>Last updated: 2025-04-20</em></p>]]></content><author><name>Manuel Alejandro Matías Astorga</name></author></entry></feed>